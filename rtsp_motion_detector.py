import cv2
import numpy as np
import os
import csv
import time
import logging
import json
import simpleaudio as sa
from concurrent.futures import ThreadPoolExecutor
from ultralytics import YOLO

# ===================== –ù–ê–°–¢–†–û–ô–ö–ò =====================
SENSITIVITY = 25
MIN_AREA = 800
PLAYBACK_SPEED = 8  # —á–µ–º –≤—ã—à–µ, —Ç–µ–º –º–µ–Ω—å—à–µ –Ω–∞–≥—Ä—É–∑–∫–∞
SAVE_FRAMES = True
SAVE_DELAY_SEC = 2
RECOGNITION_DELAY_SEC = 4
OUTPUT_FILE = "rtsp_motions_log.csv"
FRAMES_DIR = "rtsp_motion_frames"
MAX_THREADS = 4
YOLO_MODEL = "yolov8n.pt"
CONF_THRESHOLD = 0.7
ALARM_FILE = "icq.wav"
TARGET_CLASSES = ["person", "cat", "dog"]
ALARM_COOLDOWN = 6  # –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω—ã–º —Å–∏–≥–Ω–∞–ª–æ–º

# –û–∫–Ω–æ –¥–ª—è –ø–æ–∫–∞–∑–∞ –¥–≤–∏–∂–µ–Ω–∏—è
DISPLAY_WINDOW_NAME = "–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –¥–≤–∏–∂–µ–Ω–∏–µ"
DISPLAY_DURATION = 3  # —Å–µ–∫—É–Ω–¥—ã
DISPLAY_WIDTH = 800
DISPLAY_HEIGHT = 600

# –õ–æ–≥–≥–µ—Ä
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    handlers=[
        logging.FileHandler("motion_debug.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
os.makedirs(FRAMES_DIR, exist_ok=True)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
last_detection = {}  # {camera_name: {"class": str, "time": float}}
last_display_time = 0
display_frame = np.zeros((DISPLAY_HEIGHT, DISPLAY_WIDTH, 3), dtype=np.uint8)
SHOW_WINDOW = False
PLAY_ALARM = False

# –ó–∞–≥—Ä—É–∑–∫–∞ YOLO
logging.info("üì¶ –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å YOLOv8...")
model = YOLO(YOLO_MODEL)

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ CSV
if not os.path.exists(OUTPUT_FILE):
    with open(OUTPUT_FILE, mode="w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["camera", "timestamp", "class", "confidence"])


def play_alarm():
    if not PLAY_ALARM:
        return
    try:
        wave_obj = sa.WaveObject.from_wave_file(ALARM_FILE)
        wave_obj.play()
    except Exception as e:
        logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∏–≥—Ä–∞—Ç—å —Å–∏–≥–Ω–∞–ª: {e}")


def update_display(frame):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –æ–±—â–µ–≥–æ –æ–∫–Ω–∞."""
    global last_display_time, display_frame
    if SHOW_WINDOW:
        resized = cv2.resize(frame, (DISPLAY_WIDTH, DISPLAY_HEIGHT))
        display_frame = resized
        last_display_time = time.time()


def display_loop():
    """–ü–æ—Å—Ç–æ—è–Ω–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç –æ–±—â–µ–µ –æ–∫–Ω–æ, –ø–æ–∫–∞ –∏–¥—ë—Ç —Ä–∞–±–æ—Ç–∞."""
    while SHOW_WINDOW:
        now = time.time()
        if now - last_display_time > DISPLAY_DURATION:
            frame_to_show = np.zeros((DISPLAY_HEIGHT, DISPLAY_WIDTH, 3), dtype=np.uint8)
        else:
            frame_to_show = display_frame
        cv2.imshow(DISPLAY_WINDOW_NAME, frame_to_show)
        if cv2.waitKey(1) & 0xFF == ord("q"):
            break
    cv2.destroyAllWindows()


def detect_motion_and_objects(camera_name, rtsp_url):
    global last_detection
    try:
        logging.info(f"‚ñ∂ –ü–æ–¥–∫–ª—é—á–∞—é—Å—å –∫ –∫–∞–º–µ—Ä–µ {camera_name}")
        cap = cv2.VideoCapture(rtsp_url, cv2.CAP_FFMPEG)
        if not cap.isOpened():
            logging.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ {camera_name}")
            return

        ret, frame1 = cap.read()
        ret, frame2 = cap.read()

        last_save_time = 0
        last_recognition_time = 0
        frame_count = 0

        while ret:
            if frame_count % PLAYBACK_SPEED != 0:
                frame1 = frame2
                ret, frame2 = cap.read()
                frame_count += 1
                continue

            # –ê–Ω–∞–ª–∏–∑ –¥–≤–∏–∂–µ–Ω–∏—è –Ω–∞ —É–º–µ–Ω—å—à–µ–Ω–Ω—ã—Ö –∫–∞–¥—Ä–∞—Ö –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ CPU
            small1 = cv2.resize(frame1, (640, 360))
            small2 = cv2.resize(frame2, (640, 360))
            diff = cv2.absdiff(small1, small2)
            gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
            blur = cv2.GaussianBlur(gray, (5, 5), 0)
            _, thresh = cv2.threshold(blur, SENSITIVITY, 255, cv2.THRESH_BINARY)
            dilated = cv2.dilate(thresh, None, iterations=3)
            contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

            motion_detected = any(cv2.contourArea(c) >= MIN_AREA for c in contours)

            if motion_detected and (time.time() - last_recognition_time >= RECOGNITION_DELAY_SEC):
                last_recognition_time = time.time()

                # –ó–∞–ø—É—Å–∫ YOLO
                results = model(frame2, verbose=False)[0]
                for box in results.boxes:
                    cls_id = int(box.cls[0])
                    class_name = results.names[cls_id]
                    conf = float(box.conf[0])

                    if class_name in TARGET_CLASSES and conf >= CONF_THRESHOLD:
                        ts = time.strftime("%Y-%m-%d %H:%M:%S")
                        logging.info(f"üßç {class_name} ({conf:.2f}) –Ω–∞ {camera_name} –≤ {ts}")

                        # –ê–Ω—Ç–∏-—Å–ø–∞–º
                        prev = last_detection.get(camera_name, {})
                        if (prev.get("class") != class_name) or (time.time() - prev.get("time", 0) > ALARM_COOLDOWN):
                            play_alarm()
                            last_detection[camera_name] = {"class": class_name, "time": time.time()}

                        # –ü–æ–∫–∞–∑ –∫–∞–¥—Ä–∞ –≤ –æ–∫–Ω–µ
                        update_display(frame2)

                        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–¥—Ä–∞
                        if SAVE_FRAMES and (time.time() - last_save_time >= SAVE_DELAY_SEC):
                            frame_file = os.path.join(FRAMES_DIR, f"{camera_name}_{ts.replace(':','-')}_{class_name}.jpg")
                            cv2.imwrite(frame_file, frame2)
                            last_save_time = time.time()

                        # –ó–∞–ø–∏—Å—å –≤ CSV
                        with open(OUTPUT_FILE, mode="a", newline="", encoding="utf-8") as f:
                            writer = csv.writer(f)
                            writer.writerow([camera_name, ts, class_name, f"{conf:.2f}"])
                        break

            frame1 = frame2
            ret, frame2 = cap.read()
            frame_count += 1

        cap.release()

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {camera_name}: {e}")


def main():
    global SHOW_WINDOW, PLAY_ALARM

    # –í–æ–ø—Ä–æ—Å—ã –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    PLAY_ALARM = input("–ü—Ä–æ–∏–≥—Ä—ã–≤–∞—Ç—å –∑–≤—É–∫–æ–≤–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ? (y/n): ").strip().lower() == "y"
    SHOW_WINDOW = input("–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –∫–∞–¥—Ä—ã —Å –¥–≤–∏–∂–µ–Ω–∏–µ–º? (y/n): ").strip().lower() == "y"

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–º–µ—Ä
    with open("cameras.json", "r", encoding="utf-8") as f:
        cameras = json.load(f)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–∏—Å–ª–∞ –∫–∞–º–µ—Ä
    if len(cameras) > MAX_THREADS:
        logging.error(f"–í –∫–æ–Ω—Ñ–∏–≥–µ {len(cameras)} –∫–∞–º–µ—Ä, –Ω–æ –º–æ–∂–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –º–∞–∫—Å–∏–º—É–º {MAX_THREADS} –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ!")
        return

    logging.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(cameras)} –∫–∞–º–µ—Ä. –ó–∞–ø—É—Å–∫–∞—é –≤ {len(cameras)} –ø–æ—Ç–æ–∫(–∞—Ö)...")

    # –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞ –ø–æ–∫–∞–∑–∞ –æ–∫–Ω–∞, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if SHOW_WINDOW:
        cv2.namedWindow(DISPLAY_WINDOW_NAME, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(DISPLAY_WINDOW_NAME, DISPLAY_WIDTH, DISPLAY_HEIGHT)
        import threading
        threading.Thread(target=display_loop, daemon=True).start()

    # –ó–∞–ø—É—Å–∫ –∫–∞–º–µ—Ä
    with ThreadPoolExecutor(max_workers=len(cameras)) as executor:
        for name, url in cameras.items():
            executor.submit(detect_motion_and_objects, name, url)

    logging.info("‚úÖ –†–∞–±–æ—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")


if __name__ == "__main__":
    main()
